[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello Reader, thanks for clicking on my blog! My name is Simon Heitin and I’ve been a professional data scientist for 7 years. My academic and career journey has taken me from pure mathematics to systems engineering to operations research to data science.\nThe name for the blog, “Names Are Hard,” is a nod to the blinking cursor moment when you are compelled to summarize a piece of work in a single word or phrase. In coding, this moment is ubiquitous as it arises each time you create a variable, start a new project, or save a file1. You want the name to be clear but also short so that it is easy to type. You want it to be specific so that it accurately characterizes its contents, but you also want to leave space for generalization and reusability2.\nGood names have the illusion of having appeared effortlessly. “Of course you would name it that, what else in the world would you name it?” And yet, naming well usually requires a good deal of thought and often a willingness to rename and rework. So, when the cursor starts blinking, remember to take a moment to acknowledge that you confront a difficult and important task because Names Are Hard."
  },
  {
    "objectID": "about.html#footnotes",
    "href": "about.html#footnotes",
    "title": "About",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nor start a blog…hypothetically.↩︎\noh how satisfying to wrap up repeated code in a meaningful function↩︎"
  },
  {
    "objectID": "posts/ok-claude/index.html",
    "href": "posts/ok-claude/index.html",
    "title": "Ok Claude, Come on In",
    "section": "",
    "text": "Recently, I have been playing with AI tools, trying out different ways of integrating them into my workflow. My most comfortable environment is using the RStudio IDE, Quarto, and the tidyverse to wrangle data and build plots to tell a story. After quite a bit of trial and error, I landed on the following additions to this setup:\nAs with any new tool, the best way to know if it is useful is to try to use it to solve problems.\nSo, I picked up the latest Tidy Tuesday dataset and did some Exploratory Data Analysis (EDA). I didn’t start with the LLM right away though. I am pretty quick at exploring data with the tidyverse and building plots using ggplot2. So, I used my normal workflow (non-AI-assisted) to decide what I wanted to convey with my plot and get to iterating.\nAnd this is where I hit a familiar problem. There are endless options for tweaking plots, and with even a dash of perfectionist tendency, you can get stuck making endless minor adjustments. After trying my tenth different combination of height/width ratio, I asked the LLM for help breaking out of this cycle.\nI pointed it to my code and prompted: “give me four different versions of this plot.” It responded within about 10 seconds and it took me a minute or two to review the results.\nShow the code\nlibrary(tidyverse)\nlibrary(ggtext)\n\n# Grab data from GH\nvesuvius &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-05-13/vesuvius.csv') |&gt;\n  select(-type, -area) |&gt;  # is always \"earthquake\" and \"Mount Vesuvius\" \n  mutate(time_unix = time - ymd_hms(\"1970-01-01 00:00:00\"),\n         obs_day = as.Date(time)) |&gt;\n  filter(obs_day &gt;= ymd(\"2013-01-01\")) # data is very sparse before this\n\n# Fill in missing dates\nall_days &lt;- tibble(\n  obs_day = seq.Date(from = ymd(\"2013-01-01\"), to = ymd(\"2024-12-31\"), by = \"day\")\n  )\n\n# for date breaks\nbreaks &lt;- as.Date(ymd(c(\"2013-01-01\",\n                        #\"2014-01-01\", \n                        \"2015-01-01\",\n                        #\"2016-01-01\",\n                        \"2017-01-01\",\n                        #\"2018-01-01\",\n                        \"2019-01-01\",\n                        #\"2020-01-01\",\n                        \"2021-01-01\",\n                        #\"2022-01-01\",\n                        \"2023-01-01\",\n                        #\"2024-01-01\",\n                        \"2025-01-01\")))\n\n# Aggregated stats\nvesuvius_agg &lt;- vesuvius |&gt;\n  summarize(n = n(),\n            .by = obs_day) |&gt;\n  right_join(all_days, by = \"obs_day\") |&gt;\n  mutate(n = replace_na(n,0)) |&gt;\n  arrange(desc(n)) |&gt;\n  mutate(top_ten = case_when(\n    row_number() &lt;= 10 ~ \"top\",\n    row_number() &gt; 10 ~ \"not top\"))\n\n# set up our colors\npop_color &lt;- \"orange\"\ncolor_list &lt;- c(\"top\" = pop_color,\n  \"not top\" = \"grey\")\n\ndaily_plot &lt;- vesuvius_agg |&gt;\n  ggplot(aes(x = obs_day, y = n)) +\n  geom_col(aes(fill = top_ten)) +\n  geom_text(data = ~ filter(.x, top_ten == \"top\"), \n            aes(label = obs_day),\n            size = 3,\n            hjust = -.1,\n            angle = 10,\n            color = pop_color) +\n  scale_fill_manual(values = color_list) +\n  theme_dark() +\n  labs(y = \"# of Earthquakes\",\n       x = \"Date\",\n       title = \"Earthquake Activity Near Mt Vesuvius Over Time\",\n       subtitle = \"&lt;span style = 'color: DarkOrange;'&gt;Top Ten Most Active Days&lt;/span&gt; \",\n       alt = \"A bar plot of with the number of daily earthquakes near Mt. Vesuvius from 2013 to 2025. The top ten most active days are colored orange and they range from about 50 earthquakes to about 150 earthquakes. The rest of the days are in grey and they are much lower, mostly around 1 or 2.\") +\n  scale_x_date(breaks = breaks,\n               date_labels = \"%Y\") +\n  theme(panel.grid.minor = element_blank(),\n        panel.grid.major = element_blank(),\n        plot.subtitle = ggtext::element_markdown()) +\n  guides(fill = \"none\")\n\ndaily_plot\n\n\n\n\n\nMy Original Plot"
  },
  {
    "objectID": "posts/ok-claude/index.html#results",
    "href": "posts/ok-claude/index.html#results",
    "title": "Ok Claude, Come on In",
    "section": "Results",
    "text": "Results\nThree of the AI-generated plots were time series plots very similar to mine. One added a kernel density, one other removed some text labels, and the third one faceted the time series by year.\nThe fourth AI-generated plot was a calendar heatmap. It didn’t strike me as promising, but I appreciated that it was different."
  },
  {
    "objectID": "posts/ok-claude/index.html#four-ai-generated-variations",
    "href": "posts/ok-claude/index.html#four-ai-generated-variations",
    "title": "Ok Claude, Come on In",
    "section": "Four AI-Generated Variations",
    "text": "Four AI-Generated Variations\nBelow I tried to keep the raw AI results intact as much as possible. I did some formatting so that they did display similarly to what I saw when I initially ran them in the RStudio IDE.\n\nVersion 1Version 2Version 3Version 4\n\n\n\nVersion 1: Basic Time Series Plot of Daily Seismic Events\n\n\nShow the code\n# Version 1: Basic time series plot\ndaily_plot_v1 &lt;- ggplot(vesuvius_agg, aes(x = obs_day, y = n)) +\n  geom_line(color = \"grey50\") +\n  geom_point(aes(color = top_ten), size = 1) +\n  scale_color_manual(values = color_list) +\n  scale_x_date(breaks = breaks, date_labels = \"%Y\") +\n  labs(title = \"Daily Seismic Events at Mount Vesuvius (2013-2024)\",\n       x = \"Date\", \n       y = \"Number of Events\",\n       color = \"Event Count\") +\n  theme_minimal()\n\ndaily_plot_v1\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersion 2: Enhanced Time Series with Highlighted Periods and Smoother\n\n\nShow the code\n# Version 2: Enhanced with smoother and highlighted periods\ndaily_plot_v2 &lt;- ggplot(vesuvius_agg, aes(x = obs_day, y = n)) +\n  geom_line(color = \"grey70\") +\n  geom_smooth(method = \"loess\", span = 0.1, se = FALSE, color = \"steelblue\") +\n  geom_point(data = subset(vesuvius_agg, top_ten == \"top\"), \n             aes(color = top_ten), size = 2) +\n  scale_color_manual(values = color_list) +\n  geom_text(data = ~ filter(.x, top_ten == \"top\"), \n            aes(label = obs_day),\n            size = 3,\n            hjust = -.1,\n            angle = 10,\n            color = pop_color) +\n  scale_x_date(breaks = breaks, date_labels = \"%Y\") +\n  labs(title = \"Vesuvius Seismic Activity (2013-2024)\",\n       x = \"Date\", \n       y = \"Number of Events\") +\n  theme_light() +\n  theme(legend.position = \"bottom\",\n        plot.subtitle = ggtext::element_markdown()) +\n  guides(color = \"none\")\n\ndaily_plot_v2\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersion 3: Faceted Plot by Year with Density Ridges\n\n\nShow the code\n# Version 3: Faceted by year with summarized data\ndaily_plot_v3 &lt;- ggplot(vesuvius_agg, aes(x = obs_day, y = n)) +\n  geom_col(aes(fill = top_ten), width = 1) +\n  scale_fill_manual(values = color_list) +\n  facet_wrap(~ format(obs_day, \"%Y\"), scales = \"free_x\", ncol = 2) +\n  labs(title = \"Yearly Seismic Activity at Vesuvius\",\n       x = \"Date within Year\", \n       y = \"Number of Events\",\n       fill = \"Activity Level\") +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\ndaily_plot_v3\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersion 4: Heatmap Calendar View\n\n\nShow the code\n# Version 4: Calendar heatmap view\n# Create year and month variables\nvesuvius_agg_cal &lt;- vesuvius_agg %&gt;%\n  mutate(\n    year = lubridate::year(obs_day),\n    month = lubridate::month(obs_day),\n    day = lubridate::day(obs_day)\n  )\n\ndaily_plot_v4 &lt;- ggplot(vesuvius_agg_cal, \n       aes(x = day, y = month, fill = n)) +\n  geom_tile(color = \"white\", size = 0.1) +\n  scale_fill_gradient(low = \"white\", high = pop_color) +\n  facet_wrap(~ year, ncol = 3) +\n  scale_y_continuous(breaks = 1:12,\n                    labels = month.abb,\n                    trans = \"reverse\") +\n  labs(title = \"Calendar View of Vesuvius Seismic Activity\",\n       x = \"Day of Month\", \n       y = \"Month\",\n       fill = \"Event Count\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\ndaily_plot_v4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLots of Small Changes\nI knew that LLMs were non-deterministic and to be ready for possibly wild results. But, what I hadn’t considered was that it would also make a lot of smaller, somewhat arbitrary changes. Some examples:\n\nThe label “# of Earthquakes” became “Number of Events”\nThe title “Earthquake Activity Near Mt Vesuvius Over Time” became “Vesuvius Seismic Activity (2013-2024)” or “Daily Seismic Events at Mount Vesuvius (2013-2024)”\nIt summarily dropped the Alt Text label\n\nThe most helpful result: One of the LLM-generated time series plots added points to the observations I wanted to highlight, and they looked nice. In my version, I used color and had a text callout but not points. A small change, but I liked it.\n\n\nOne Funky Code Smell\nI actually ran the prompt a couple of times and the results were fairly similar each time with one exception: one version wrapped each of the plot objects in a function call. This is a fine practice in general, but the LLM made the strange choice of adding library calls inside of each function.\nThe sneaky thing about this is that the code will run, but it’s not a pattern any seasoned R programmer would recommend. A new R programmer, though, might be tripped up.\nMore than anything, this was a reminder to be skeptical of the LLM output, especially when doing tasks that aren’t yet part of your expertise. In those cases, returning to documentation you trust could be a good way to check any LLM-generated patterns that look suspect."
  },
  {
    "objectID": "posts/ok-claude/index.html#making-good-choices",
    "href": "posts/ok-claude/index.html#making-good-choices",
    "title": "Ok Claude, Come on In",
    "section": "Making Good Choices",
    "text": "Making Good Choices\nUpon reflection, a few of the choices I made for this project made it likely to succeed:\n\nI chose an area that I already know well - Tidyverse wrangling and ggplot are my bread and butter. So, I was able to quickly evaluate what the LLM came up with. I could also make changes to it, knowing that I could fix anything that broke without too much trouble.\n\nIn a recent LinkedIn post, Ethan Mollick recommended this approach:\n\nThe most obvious, lowest risk way to use AI (and to get a sense of how good it is in areas that matter to you) is to ask it for second opinions in your area of expertise.\n\n\nI chose a task that was verifiable - asking it to generate code meant that I could run the code to test it.\n\nWith code, you can integrate the result into your existing product. With writing that can be harder.\n\nI chose a task that was scoped - by the time I pulled in the LLM, I already knew the point I wanted to convey. I was looking for options to convey it.\n\nRelatedly, I limited the number of turns with the LLM. I took what the LLM had to offer with some limited prompting and then got back to my normal workflow.\n\nI configured my environment before starting - I used the Ellmer and btw packages to make it easy to give the LLM my full context.\n\nI spent a whole lot of time researching different workflows and setups. This could be another set of posts and I will link below to resources that I used to do this.\nAndrew Holz mad a related recommendation in his excellent blog post “Running AI/LLM Hackathons at Posit: What We’ve Learned”:\n\nInteracting with LLMs programmatically—rather than through a chat interface or as code completion—provides deeper insight into both the challenges and the possibilities."
  },
  {
    "objectID": "posts/ok-claude/index.html#whats-next",
    "href": "posts/ok-claude/index.html#whats-next",
    "title": "Ok Claude, Come on In",
    "section": "What’s Next",
    "text": "What’s Next\nI am looking to grow as a Python programmer, and I wonder how well AI can assist in an area where I don’t have quite the same fluency. The packages and plugins I used here (Ellmer and btw) are R-specific, so I will try different Python-specific options.\nI have been playing with Continue writing Python in the Positron IDE and have had good results. One feature I like is that the Continue plugin presents code changes as actual diffs for you to accept or reject rather than immediately writing over your code.\nI have an inkling that change management is important since the LLM makes it easy to generate new code and edit existing code. It will be useful to be able to get back to a state where you know things work. I would like to try using a more deliberate git strategy to help here: frequent commits and a willingness to revert. While this would be adding yet another technology to the mix, git is very mature and I am pretty comfortable with it.\nOnward!\nSimon"
  },
  {
    "objectID": "posts/my-first-package/index.html",
    "href": "posts/my-first-package/index.html",
    "title": "My First Package",
    "section": "",
    "text": "The first package I wrote myself was terribly unexciting except for one thing: it solved a package management problem problem that was common for new or intermediate R users at my organization."
  },
  {
    "objectID": "posts/my-first-package/index.html#background---our-rstudio-server-setup",
    "href": "posts/my-first-package/index.html#background---our-rstudio-server-setup",
    "title": "My First Package",
    "section": "Background - Our RStudio Server Setup",
    "text": "Background - Our RStudio Server Setup\nWe have a fantastic team that manages our RStudio Server environment. They implement a system that provides the flexibility for folks to manage their own package libraries as well as to use a set of centrally-managed system-level packages. The system-level package library is updated each night by a script that checks for new versions of an admin-specified set of packages and installs an update if one exists.\nIn the user environment, when a user calls a package with library(a_package), .libPaths() will first look in a directory of user-managed packages. These are any packages that a user installed explicitly using install.packages() or equivalent.\nIf the package is not found in the user-managed directory, then the environment will move to the directory of system-level packages.\nA problem can arise when a user unknowingly installs a package that is a dependency for a package that is managed at the system level. While this may be fine at first, over time the system-level packages will be automatically kept current and the system-level package may depend on a newer version of the other package than what the user installed. The updated version of the dependency package will have been automatically updated in the system repository, but the user may forget to update their own version. So, when the user calls the system-managed package, the system will grab the version of the dependency package that is in their personal directory and R will throw an error.\nThis can be very confusing to users who are not used to managing their own package libraries. In fact, one of the wonderful things about our RStudio environment is that users can get really far without having to worry about package management or even know about install.packages(). They can just get coding!1"
  },
  {
    "objectID": "posts/my-first-package/index.html#an-evolving-solution",
    "href": "posts/my-first-package/index.html#an-evolving-solution",
    "title": "My First Package",
    "section": "An Evolving Solution",
    "text": "An Evolving Solution\nFor a while, my solution was to write a script that checks the system-level package directory for packages that are also installed in a user’s package directory and then delete the version in the user’s package directory. I shared this script in a code block in Slack that users could paste into the command line and run. In fact, I pinned a message with this code block in Slack so that I could find it and share it easily.\nThen, one day, one of my colleagues had an idea: what if I wrapped the script up as a function and wrote it into a package? Then, we could include the package in the system libraries and when folks needed it, they could simply call the function from the command line. Plus, we could include all of the documentation about in the package to explain what it did (for those who were interested), which would be a lot nicer to look at than a Slack thread.\nBut, I had never written a package before! Little did I know, there was a whole new world waiting for me, lovingly constructed to get users like me from “It’d be really cool to write a package” to “I just wrote my first package!” with minimal pain.\nEnter “R Packages” by Hadley Wickham and Jenny Bryan.\n\nThe R Package Development World\nThe best thing about “R Packages” is that it prods users to keep a healthy problem-solving attitude and to be gentle with themselves while they wrestle with challenging technical problems. The end of the introduction sets the tone:\n\nWriting a package can seem overwhelming at first. So start with the basics and improve it over time. It doesn’t matter if your first version isn’t perfect as long as the next version is better. - R Packages\n\nThe second best thing about “R Packages” is the accompanying package-writing packages that just make things work. devtools, usethis, and testthat are thoughtfully curated to support the workflows described in “R Packages” while providing flexibility and room for growth for advancing users.\nThe third best thing about “R Packages” is that all of it (the book, the packages, the RStudio IDE) is free and open source."
  },
  {
    "objectID": "posts/my-first-package/index.html#solution-implemented",
    "href": "posts/my-first-package/index.html#solution-implemented",
    "title": "My First Package",
    "section": "Solution Implemented",
    "text": "Solution Implemented\nAnd so, armed with fantastic documentation, technical support, and a full-day meeting with myself, I wrote my first package.\nV0.1 of libfilesmgr has one function: clean_personal_libs(). It has been used by probably a dozen users over the last couple years and there are no plans to expand the scope or enrich its function. I believe it will continue to be useful within this well-defined scope and the journey of writing it was certainly a useful experience for me to learn the mechanics of package development."
  },
  {
    "objectID": "posts/my-first-package/index.html#footnotes",
    "href": "posts/my-first-package/index.html#footnotes",
    "title": "My First Package",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nmore advanced users, or anyone looking for reproducability will want to look into the (renv)[https://rstudio.github.io/renv/articles/renv.html] package. Here’s a nice (talk)[https://www.rstudio.com/conference/2022/talks/you-should-use-renv/] on renv by E. David Aja from this year’s rstudio::conf.↩︎"
  },
  {
    "objectID": "posts/family_feud/index.html",
    "href": "posts/family_feud/index.html",
    "title": "Family Feud - NYT Crossword Edition",
    "section": "",
    "text": "If there’s one thing that unites my family, it’s a love of food1. If there are two things that unite my family, they are a love of food and a love of puzzles. So, when I saw that tidytuesday had wrangled a set of crossword clues and answers, I knew what I had to do.\nI emailed my family members and asked them to submit one guess as to what they thought was the most common 4-letter crossword answer.\nShow the code\nlibrary(tidyverse)\nlibrary(lubridate)\n\npath &lt;- \n  'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-04-19/times.csv'\n  \ntimes &lt;- read_csv(path) \n\ntimes_clean &lt;- times %&gt;% \n  mutate(answer = str_remove_all(answer, \" \"),\n         answer_len = nchar(answer)) %&gt;% \n  filter(!is.na(puzzle_date)) \n\n#these are the guesses. I provided a pseudonym for each family member to keep \n# things friendly. https://babynames.com/names/random-name-generator.php was a\n#  big help\nfam_responses_anon &lt;- data.frame(\n  stringsAsFactors = FALSE,\n               answer = c(\"ANTE\",\"ERRS\",\"HOME\",\n                          \"IDEA\",\"DERN\",\"BEAU\",\"SETS\",\"EONS\",\"ERAS\",\"TIME\",\n                          \"WELL\",\"WHAT\",\"ACRE\",\"STAG\",\"ARIL\", \"LAST\", \"CLAM\", \n                          \"FOUR\", \"WILL\", \"BALL\"),\n            pseudonym = c(\"Keona\",\"Gordian\",\"Zai\",\n                          \"Makaila\",\"Olof\",\"Quintana\",\"Selene\",\"Ceron\",\n                          \"Harrison\",\"Mignonette\",\"Tua\",\"Alysha\",\"Ziva\",\n                          \"Maddox\",\"Mervin\", \"Ultimate Warrior\", \"Janet\", \n                          \"Tarzan\", \"Spock\", \"Sally\")\n   )\n\n# get the number of occurrences for each 4-letter word\nanswers_ordered &lt;- times_clean %&gt;%\n  filter(answer_len == 4) %&gt;%\n  count(answer, name = \"n_appearances\") %&gt;%\n  arrange(desc(n_appearances)) \n\n# to calculate percentiles, we need to \nanswers_pctile &lt;- answers_ordered %&gt;%\n  count(n_appearances, name = \"n_answers\") %&gt;%\n  arrange(desc(n_appearances)) %&gt;%\n  mutate(num_better_answers = lag(cumsum(n_answers), default = 0),\n         pct_better_answers = num_better_answers / sum(n_answers),\n         pctile = 1-pct_better_answers) %&gt;%\n  right_join(answers_ordered, by = \"n_appearances\") \n\n# now just get the answers from my family\nfamily_answers_pctile &lt;- answers_pctile %&gt;%\n  right_join(fam_responses_anon, by = \"answer\") %&gt;%\n  mutate(pctile = replace_na(pctile, 0),\n         num_better_answers = replace_na(num_better_answers, 2000))"
  },
  {
    "objectID": "posts/family_feud/index.html#bum-bum-ba-da-buuuuum---results",
    "href": "posts/family_feud/index.html#bum-bum-ba-da-buuuuum---results",
    "title": "Family Feud - NYT Crossword Edition",
    "section": "Bum Bum Ba Da Buuuuum - Results",
    "text": "Bum Bum Ba Da Buuuuum - Results\nThe plot below shows the results of our challenge. The y-axis is the percentile for how common each 4-letter word is. So, if a word is in the 90th percentile, then it is more common than 90% of all 4-letter words (that appeared in at least one crossword puzzle).\n\n\nShow the code\nlibrary(ggrepel)\nlibrary(scales)\n\n family_answers_pctile %&gt;%\n  ggplot(aes(y = pctile)) +\n  geom_vline(xintercept = 0) +\n  geom_point(aes(x = 0), alpha = .3, stroke = 0) +\n  # stat_ecdf() +\n  geom_label_repel(aes(label = answer, x = 0), max.overlaps = 20, fill = \"light blue\") +\n  scale_y_continuous(labels = label_percent(), limits = c(0,1)) +\n  theme_light() +\n  theme(axis.text.x=element_blank(),\n        axis.ticks=element_blank(),\n        axis.title.x=element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank())  +\n  labs(y = \"Answer Percentile\")\n\n\n\n\n\nFamily Guesses and Their Resulting Percentiles\n\n\n\n\nA keen eye will note that the top answer, “WELL”, is at the 100th Percentile. That’s right, one family member chose the absolute most common 4-letter crossword clue! It’s no wonder that this is also the person who made a living out of playing poker through serious study and computer simulation."
  },
  {
    "objectID": "posts/family_feud/index.html#try-for-yourself",
    "href": "posts/family_feud/index.html#try-for-yourself",
    "title": "Family Feud - NYT Crossword Edition",
    "section": "Try For Yourself",
    "text": "Try For Yourself\nType an answer in ALL CAPS in the text box in the first column below. This is limited to 4-letter answers. The time range is 2012-12-27 to 2021-09-12, though the data appears to be most complete between 2017 and 2021.\n\n\nShow the code\nlibrary(reactable)\nanswers_pctile %&gt;%\n  mutate(percentile = scales::percent(pctile, accuracy = .01)) %&gt;%\n  select(`Answer` = answer, \n         `Answer Percentile` = percentile, \n         `No. of Puzzles in Which Answer Appeared` = n_appearances) %&gt;%\n  reactable::reactable(filterable = TRUE, defaultPageSize = 1)"
  },
  {
    "objectID": "posts/family_feud/index.html#footnotes",
    "href": "posts/family_feud/index.html#footnotes",
    "title": "Family Feud - NYT Crossword Edition",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nthis post is not about about food but maybe the next one should be↩︎"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Testing Out Quarto Blog",
    "section": "",
    "text": "Don’t mind me, just giving it a go with the Quarto blog capability.\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(package = 'palmerpenguins')"
  },
  {
    "objectID": "posts/post-with-code/index.html#check-out-this-plot",
    "href": "posts/post-with-code/index.html#check-out-this-plot",
    "title": "Testing Out Quarto Blog",
    "section": "Check Out This Plot!",
    "text": "Check Out This Plot!\n\npenguins %&gt;%\n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\n  geom_point()"
  },
  {
    "objectID": "posts/set-up-quarto-blog-rstudio-cloud/index.html",
    "href": "posts/set-up-quarto-blog-rstudio-cloud/index.html",
    "title": "Tip - Setting Up A Quarto Blog With RStudio Cloud",
    "section": "",
    "text": "Having just set up a Quarto blog using RStudio Cloud, I thought I’d share one challenge and work-around that was particularly useful.\nThe published instructions for creating a Quarto blog start with the following terminal command:\nThis command works beautifully, creating all of the files you will need for a Quarto blog as well as a related RStudio Project file in the myblog directory. From what I can tell, this assumes that you are in an RStudio session that does not have an active project.\nHowever, in the RStudio Cloud environment, the command line is not accessible outside of an RStudio Project. So, if you try the above command, the result will be a new folder with your quarto blog files and an RStudio Project file inside of your existing RStudio project. If you are using Github to deploy the blog, Github won’t be able to find the docs folder since it will be one level deeper than it is expecting. Oh no!\nLuckily, there is an easy fix: omit the new directory name from the terminal command. This will create the files in your root directory, which is the project directory you are already in. The new command becomes:\nHappy blogging!"
  },
  {
    "objectID": "posts/set-up-quarto-blog-rstudio-cloud/index.html#tldr---how-to-start-a-quarto-blog-in-rstudio-cloud",
    "href": "posts/set-up-quarto-blog-rstudio-cloud/index.html#tldr---how-to-start-a-quarto-blog-in-rstudio-cloud",
    "title": "Tip - Setting Up A Quarto Blog With RStudio Cloud",
    "section": "TLDR - How to Start a Quarto Blog in RStudio Cloud",
    "text": "TLDR - How to Start a Quarto Blog in RStudio Cloud\nTo recap, here are the steps: 1) Log into your RStudio Cloud 2) Start a new project 3) Enter the following command into the terminal: quarto create-project --type website:blog"
  },
  {
    "objectID": "posts/set-up-quarto-blog-rstudio-cloud/index.html#addendum",
    "href": "posts/set-up-quarto-blog-rstudio-cloud/index.html#addendum",
    "title": "Tip - Setting Up A Quarto Blog With RStudio Cloud",
    "section": "Addendum",
    "text": "Addendum\nIf, like me, you got going with your blog work following the published instructions before you realized there was an issue with the file structure, there is a command that will sort things out for you:\ncp -r myblog/* .\nThis will copy everything inside of the myblog folder to the project root directory.\nNext, you will need to delete the myblog folder since you’ve already moved its contents."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Names Are Hard",
    "section": "",
    "text": "Ok Claude, Come on In\n\n\n\n\n\n\nai\n\n\n\n\n\n\n\n\n\nMay 23, 2025\n\n\nSimon Heitin\n\n\n\n\n\n\n\n\n\n\n\n\nMy First Package\n\n\n\n\n\n\npackages\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\nSimon Heitin\n\n\n\n\n\n\n\n\n\n\n\n\nTip - Setting Up A Quarto Blog With RStudio Cloud\n\n\n\n\n\n\nquarto\n\n\nhow-to\n\n\n\n\n\n\n\n\n\nSep 29, 2022\n\n\nSimon Heitin\n\n\n\n\n\n\n\n\n\n\n\n\nFamily Feud - NYT Crossword Edition\n\n\n\n\n\n\ntidytuesday\n\n\ncode\n\n\n\n\n\n\n\n\n\nSep 28, 2022\n\n\nSimon Heitin\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Out Quarto Blog\n\n\n\n\n\n\nquarto\n\n\ncode\n\n\n\n\n\n\n\n\n\nSep 25, 2022\n\n\nSimon Heitin\n\n\n\n\n\n\nNo matching items"
  }
]